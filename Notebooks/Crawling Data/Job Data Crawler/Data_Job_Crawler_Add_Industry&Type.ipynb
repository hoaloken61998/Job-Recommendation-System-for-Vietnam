{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "OHjJaEMxnWaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright tqdm nest_asyncio openpyxl\n",
        "\n",
        "!playwright install --with-deps chromium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t0bp4deScxY",
        "outputId": "ddfedb83-5022-40aa-a2ae-a36c4007b32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playwright\n",
            "  Downloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyee<14,>=13 (from playwright)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting greenlet<4.0.0,>=3.1.1 (from playwright)\n",
            "  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<14,>=13->playwright) (4.14.0)\n",
            "Downloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl (45.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: pyee, greenlet, et-xmlfile, playwright, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 greenlet-3.2.3 openpyxl-3.1.5 playwright-1.52.0 pyee-13.0.0\n",
            "Installing dependencies...\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,249 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,556 kB]\n",
            "Fetched 21.3 MB in 2s (12.5 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libasound2 set to manually installed.\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk-bridge2.0-0 set to manually installed.\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatk1.0-0 set to manually installed.\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libatspi2.0-0 set to manually installed.\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 set to manually installed.\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 set to manually installed.\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxcomposite1 set to manually installed.\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxdamage1 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxfixes3 set to manually installed.\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxkbcommon0 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrandr2 set to manually installed.\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libcups2 set to manually installed.\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdbus-1-3 set to manually installed.\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libdrm2 set to manually installed.\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
            "libfreetype6 set to manually installed.\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libgbm1 set to manually installed.\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.5).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnspr4 set to manually installed.\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libnss3 set to manually installed.\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpango-1.0-0 set to manually installed.\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-client0 set to manually installed.\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-6 set to manually installed.\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
            "The following additional packages will be installed:\n",
            "  xfonts-encodings xfonts-utils\n",
            "Recommended packages:\n",
            "  fonts-ipafont-mincho fonts-tlwg-loma\n",
            "The following NEW packages will be installed:\n",
            "  fonts-freefont-ttf fonts-ipafont-gothic fonts-noto-color-emoji\n",
            "  fonts-tlwg-loma-otf fonts-unifont fonts-wqy-zenhei xfonts-cyrillic\n",
            "  xfonts-encodings xfonts-scalable xfonts-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 2 not upgraded.\n",
            "Need to get 28.4 MB of archives.\n",
            "After this operation, 67.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\n",
            "Fetched 28.4 MB in 1s (48.8 MB/s)\n",
            "Selecting previously unselected package fonts-ipafont-gothic.\n",
            "(Reading database ... 121954 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\n",
            "Unpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../1-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../2-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-tlwg-loma-otf.\n",
            "Preparing to unpack .../3-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\n",
            "Unpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Selecting previously unselected package fonts-unifont.\n",
            "Preparing to unpack .../4-fonts-unifont_1%3a14.0.01-1_all.deb ...\n",
            "Unpacking fonts-unifont (1:14.0.01-1) ...\n",
            "Selecting previously unselected package fonts-wqy-zenhei.\n",
            "Preparing to unpack .../5-fonts-wqy-zenhei_0.9.45-8_all.deb ...\n",
            "Unpacking fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../6-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../7-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-cyrillic.\n",
            "Preparing to unpack .../8-xfonts-cyrillic_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-cyrillic (1:1.0.5) ...\n",
            "Selecting previously unselected package xfonts-scalable.\n",
            "Preparing to unpack .../9-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\n",
            "Unpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Setting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Setting up fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
            "Setting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
            "Setting up fonts-unifont (1:14.0.01-1) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-cyrillic (1:1.0.5) ...\n",
            "Setting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Downloading Chromium 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G167.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 0% 48.9s\u001b[0K\u001b[1G167.7 MiB [] 0% 27.4s\u001b[0K\u001b[1G167.7 MiB [] 0% 16.1s\u001b[0K\u001b[1G167.7 MiB [] 0% 8.6s\u001b[0K\u001b[1G167.7 MiB [] 1% 4.6s\u001b[0K\u001b[1G167.7 MiB [] 3% 3.1s\u001b[0K\u001b[1G167.7 MiB [] 4% 2.4s\u001b[0K\u001b[1G167.7 MiB [] 5% 2.1s\u001b[0K\u001b[1G167.7 MiB [] 7% 1.9s\u001b[0K\u001b[1G167.7 MiB [] 8% 1.7s\u001b[0K\u001b[1G167.7 MiB [] 10% 1.6s\u001b[0K\u001b[1G167.7 MiB [] 12% 1.4s\u001b[0K\u001b[1G167.7 MiB [] 14% 1.3s\u001b[0K\u001b[1G167.7 MiB [] 15% 1.2s\u001b[0K\u001b[1G167.7 MiB [] 17% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 18% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 20% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 21% 1.1s\u001b[0K\u001b[1G167.7 MiB [] 23% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 25% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 27% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 28% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 29% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 30% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 31% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 33% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 34% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 35% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 37% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 38% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 38% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 39% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 39% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 40% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 41% 1.0s\u001b[0K\u001b[1G167.7 MiB [] 42% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 44% 0.9s\u001b[0K\u001b[1G167.7 MiB [] 46% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 47% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 48% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 50% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 51% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 52% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 53% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 54% 0.8s\u001b[0K\u001b[1G167.7 MiB [] 55% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 57% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 58% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 59% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 60% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 61% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 62% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 63% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 64% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 65% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 66% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 67% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 69% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 70% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 70% 0.7s\u001b[0K\u001b[1G167.7 MiB [] 71% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 73% 0.6s\u001b[0K\u001b[1G167.7 MiB [] 75% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 77% 0.5s\u001b[0K\u001b[1G167.7 MiB [] 79% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 80% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 81% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 82% 0.4s\u001b[0K\u001b[1G167.7 MiB [] 84% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 86% 0.3s\u001b[0K\u001b[1G167.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 90% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 92% 0.2s\u001b[0K\u001b[1G167.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 97% 0.1s\u001b[0K\u001b[1G167.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G167.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium-1169\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 2% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 10% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 25% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 58% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Downloading Chromium Headless Shell 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G101.4 MiB [] 0% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 0% 31.0s\u001b[0K\u001b[1G101.4 MiB [] 0% 23.5s\u001b[0K\u001b[1G101.4 MiB [] 0% 11.9s\u001b[0K\u001b[1G101.4 MiB [] 1% 6.7s\u001b[0K\u001b[1G101.4 MiB [] 2% 3.4s\u001b[0K\u001b[1G101.4 MiB [] 4% 2.2s\u001b[0K\u001b[1G101.4 MiB [] 6% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 6% 2.1s\u001b[0K\u001b[1G101.4 MiB [] 6% 2.3s\u001b[0K\u001b[1G101.4 MiB [] 6% 2.5s\u001b[0K\u001b[1G101.4 MiB [] 7% 2.5s\u001b[0K\u001b[1G101.4 MiB [] 8% 2.4s\u001b[0K\u001b[1G101.4 MiB [] 9% 2.5s\u001b[0K\u001b[1G101.4 MiB [] 9% 2.6s\u001b[0K\u001b[1G101.4 MiB [] 10% 2.5s\u001b[0K\u001b[1G101.4 MiB [] 11% 2.3s\u001b[0K\u001b[1G101.4 MiB [] 13% 2.1s\u001b[0K\u001b[1G101.4 MiB [] 14% 2.1s\u001b[0K\u001b[1G101.4 MiB [] 16% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 17% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 19% 1.7s\u001b[0K\u001b[1G101.4 MiB [] 21% 1.6s\u001b[0K\u001b[1G101.4 MiB [] 21% 1.7s\u001b[0K\u001b[1G101.4 MiB [] 22% 1.6s\u001b[0K\u001b[1G101.4 MiB [] 23% 1.6s\u001b[0K\u001b[1G101.4 MiB [] 23% 1.7s\u001b[0K\u001b[1G101.4 MiB [] 24% 1.7s\u001b[0K\u001b[1G101.4 MiB [] 25% 1.8s\u001b[0K\u001b[1G101.4 MiB [] 25% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 26% 1.9s\u001b[0K\u001b[1G101.4 MiB [] 26% 2.0s\u001b[0K\u001b[1G101.4 MiB [] 29% 1.8s\u001b[0K\u001b[1G101.4 MiB [] 31% 1.7s\u001b[0K\u001b[1G101.4 MiB [] 32% 1.6s\u001b[0K\u001b[1G101.4 MiB [] 34% 1.6s\u001b[0K\u001b[1G101.4 MiB [] 35% 1.5s\u001b[0K\u001b[1G101.4 MiB [] 37% 1.4s\u001b[0K\u001b[1G101.4 MiB [] 38% 1.4s\u001b[0K\u001b[1G101.4 MiB [] 39% 1.3s\u001b[0K\u001b[1G101.4 MiB [] 41% 1.3s\u001b[0K\u001b[1G101.4 MiB [] 42% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 44% 1.2s\u001b[0K\u001b[1G101.4 MiB [] 45% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 47% 1.1s\u001b[0K\u001b[1G101.4 MiB [] 48% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 49% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 51% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 52% 1.0s\u001b[0K\u001b[1G101.4 MiB [] 54% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 55% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 56% 0.9s\u001b[0K\u001b[1G101.4 MiB [] 59% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 61% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 61% 0.8s\u001b[0K\u001b[1G101.4 MiB [] 63% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 64% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 65% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 66% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 67% 0.7s\u001b[0K\u001b[1G101.4 MiB [] 68% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 70% 0.6s\u001b[0K\u001b[1G101.4 MiB [] 72% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 73% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 74% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 75% 0.5s\u001b[0K\u001b[1G101.4 MiB [] 77% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 78% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 79% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 80% 0.4s\u001b[0K\u001b[1G101.4 MiB [] 82% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 83% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 84% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 85% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 86% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 87% 0.3s\u001b[0K\u001b[1G101.4 MiB [] 88% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 90% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 91% 0.2s\u001b[0K\u001b[1G101.4 MiB [] 92% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 94% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 95% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 96% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 97% 0.1s\u001b[0K\u001b[1G101.4 MiB [] 98% 0.0s\u001b[0K\u001b[1G101.4 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqIDQ0uqNf0K"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import pandas as pd\n",
        "from playwright.async_api import async_playwright, Page, BrowserContext\n",
        "from tqdm.asyncio import tqdm_asyncio\n",
        "import nest_asyncio\n",
        "from google.colab import files\n",
        "from google.colab import data_table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/df_hinhthuc_null.csv\")"
      ],
      "metadata": {
        "id": "NeZB9Y0BdIpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions for Industry and Type"
      ],
      "metadata": {
        "id": "DeU5YzU9nZkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions to Scrape Specific Details ---\n",
        "# get_nganh_nghe_from_page and get_hinh_thuc_from_page remain THE SAME as in your notebook.\n",
        "# I'm including them here for completeness of the runnable cell.\n",
        "async def get_nganh_nghe_from_page(page: Page) -> str:\n",
        "    try:\n",
        "        label_element = await page.query_selector(\"xpath=//li[.//strong[contains(normalize-space(.), 'Ngành nghề')]]\")\n",
        "        if label_element:\n",
        "            value_element = await label_element.query_selector(\"p > a\")\n",
        "            if value_element:\n",
        "                text = (await value_element.inner_text()).strip()\n",
        "                if text: return text\n",
        "        strong_nganh_nghe = await page.query_selector(\"xpath=//strong[contains(normalize-space(.), 'Ngành nghề')]\")\n",
        "        if strong_nganh_nghe:\n",
        "            parent_li = await strong_nganh_nghe.query_selector(\"xpath=ancestor::li\")\n",
        "            if parent_li:\n",
        "                 p_tag = await parent_li.query_selector(\"p\")\n",
        "                 if p_tag:\n",
        "                    a_tag = await p_tag.query_selector(\"a\")\n",
        "                    if a_tag:\n",
        "                        text = (await a_tag.inner_text()).strip()\n",
        "                        if text: return text\n",
        "            else:\n",
        "                p_sibling = await strong_nganh_nghe.query_selector(\"xpath=./following-sibling::p[1]\")\n",
        "                if p_sibling:\n",
        "                    a_tag = await p_sibling.query_selector(\"a\")\n",
        "                    if a_tag:\n",
        "                        text = (await a_tag.inner_text()).strip()\n",
        "                        if text: return text\n",
        "    except Exception as e:\n",
        "        print(f\"LỖI (Ngành nghề) {page.url}: {e}\")\n",
        "    return \"N/A\"\n",
        "\n",
        "async def get_hinh_thuc_from_page(page: Page) -> str:\n",
        "    try:\n",
        "        label_element = await page.query_selector(\"xpath=//li[.//strong[contains(normalize-space(.), 'Hình thức')]]\")\n",
        "        if label_element:\n",
        "            value_element = await label_element.query_selector(\"p\")\n",
        "            if value_element:\n",
        "                text = (await value_element.inner_text()).strip()\n",
        "                if text: return text\n",
        "        strong_hinh_thuc = await page.query_selector(\"xpath=//strong[contains(normalize-space(.), 'Hình thức')]\")\n",
        "        if strong_hinh_thuc:\n",
        "            parent_li = await strong_hinh_thuc.query_selector(\"xpath=ancestor::li\")\n",
        "            if parent_li:\n",
        "                p_tag = await parent_li.query_selector(\"p\")\n",
        "                if p_tag:\n",
        "                    text = (await p_tag.inner_text()).strip()\n",
        "                    if text: return text\n",
        "            else:\n",
        "                p_sibling = await strong_hinh_thuc.query_selector(\"xpath=./following-sibling::p[1]\")\n",
        "                if p_sibling:\n",
        "                    text = (await p_sibling.inner_text()).strip()\n",
        "                    if text: return text\n",
        "    except Exception as e:\n",
        "        print(f\"LỖI (Hình thức) {page.url}: {e}\")\n",
        "    return \"N/A\"\n",
        "\n",
        "async def fetch_single_url_details(url: str, context: BrowserContext, semaphore: asyncio.Semaphore) -> dict:\n",
        "    \"\"\"\n",
        "    Worker function to fetch details for a single URL.\n",
        "    Manages its own page within the given browser context.\n",
        "    \"\"\"\n",
        "    async with semaphore: # Acquire semaphore before creating a page\n",
        "        page = None\n",
        "        nganh_nghe = \"N/A\"\n",
        "        hinh_thuc = \"N/A\"\n",
        "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
        "            print(f\"URL không hợp lệ, bỏ qua: {url}\")\n",
        "            return {\"URL\": url, \"NganhNghe\": \"Invalid URL\", \"HinhThuc\": \"Invalid URL\"}\n",
        "        try:\n",
        "            page = await context.new_page()\n",
        "            # Abort image and CSS requests for speed\n",
        "            await page.route(\"**/*.{png,jpg,jpeg,gif,webp,css,woff,woff2,svg}\", lambda route: route.abort())\n",
        "\n",
        "            await page.goto(url, wait_until=\"domcontentloaded\", timeout=45000) # domcontentloaded is faster\n",
        "            # Consider a small explicit wait if data isn't always present immediately\n",
        "            # await page.wait_for_timeout(500)\n",
        "\n",
        "            nganh_nghe = await get_nganh_nghe_from_page(page)\n",
        "            hinh_thuc = await get_hinh_thuc_from_page(page)\n",
        "\n",
        "            # Optional: print success for each URL if needed for debugging, can be noisy\n",
        "            # print(f\"DONE: {url} -> Ngành: {nganh_nghe}, Hình thức: {hinh_thuc}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi nghiêm trọng khi xử lý URL {url}: {e}\")\n",
        "            nganh_nghe = f\"Lỗi: {str(e)[:50]}\"\n",
        "            hinh_thuc = f\"Lỗi: {str(e)[:50]}\"\n",
        "        finally:\n",
        "            if page:\n",
        "                await page.close()\n",
        "            # Small delay before releasing semaphore to be nice to the server\n",
        "            # This sleep is now per concurrent worker, not per URL sequentially.\n",
        "            await asyncio.sleep(0.5) # Reduced sleep as it's within concurrent tasks\n",
        "\n",
        "        return {\"URL\": url, \"NganhNghe\": nganh_nghe, \"HinhThuc\": hinh_thuc}\n",
        "\n",
        "async def scrape_job_details_concurrently(job_urls: list, concurrency: int = 5) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Scrapes 'Ngành nghề' and 'Hình thức' for a list of job URLs concurrently.\n",
        "    \"\"\"\n",
        "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"\n",
        "    semaphore = asyncio.Semaphore(concurrency) # Limit concurrent tasks\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        context = await browser.new_context(user_agent=user_agent, java_script_enabled=True)\n",
        "        # No need to create a page here, workers will create their own\n",
        "\n",
        "        tasks = [fetch_single_url_details(url, context, semaphore) for url in job_urls]\n",
        "\n",
        "        results = []\n",
        "        # Using tqdm for progress bar with asyncio.gather\n",
        "        for future in tqdm_asyncio(asyncio.as_completed(tasks), total=len(tasks), desc=\"Scraping job details\"):\n",
        "            result = await future\n",
        "            results.append(result)\n",
        "\n",
        "        await context.close() # Close context first\n",
        "        await browser.close()\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "kCzh4_MBOYL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution ---\n",
        "async def main():\n",
        "    # Using the DataFrame 'df' loaded in Cell 3\n",
        "    if df.empty or 'URL' not in df.columns:\n",
        "        print(\"DataFrame 'df' is empty or does not contain a 'URL' column. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Taking all URLs from the loaded df.\n",
        "    # If you were using the partitioning logic, list_of_job_urls would be pre-filtered.\n",
        "    # For this example, let's assume df contains the URLs for the current part/file.\n",
        "    list_of_job_urls = df[\"URL\"].dropna().unique().tolist() # Get unique, non-null URLs\n",
        "\n",
        "    # You can take a slice for testing, e.g., list_of_job_urls = list_of_job_urls[:20]\n",
        "    # list_of_job_urls = df[\"URL\"][:5].to_list() # As in your original example for testing\n",
        "\n",
        "    if not list_of_job_urls:\n",
        "        print(\"Danh sách URL trống sau khi lọc. Vui lòng cung cấp URL để cào dữ liệu.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Bắt đầu cào dữ liệu cho {len(list_of_job_urls)} URLs...\")\n",
        "\n",
        "    # Adjust concurrency based on Colab's stability. 3-5 is a safe start.\n",
        "    # Higher might be faster if Colab handles it, but can also lead to crashes/blocks.\n",
        "    CONCURRENCY_LEVEL = 4\n",
        "    detailed_df = await scrape_job_details_concurrently(list_of_job_urls, concurrency=CONCURRENCY_LEVEL)\n",
        "\n",
        "    print(\"\\n--- Kết quả cào dữ liệu ---\")\n",
        "    if not detailed_df.empty:\n",
        "        from google.colab import data_table\n",
        "        display(data_table.DataTable(detailed_df, include_index=False, num_rows_per_page=10))\n",
        "\n",
        "        output_filename = \"careerviet_nganh_nghe_hinh_thuc_CONCURRENT.xlsx\"\n",
        "        detailed_df.to_excel(output_filename, index=False, engine='openpyxl')\n",
        "        print(f\"\\nDữ liệu đã được lưu vào file: {output_filename}\")\n",
        "    else:\n",
        "        print(\"Không có dữ liệu nào được cào.\")"
      ],
      "metadata": {
        "id": "Y5ccKAsWOuzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngzKe_qCvjs9",
        "outputId": "c4f2f490-95cd-4578-ace9-12bf81caf8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bắt đầu cào dữ liệu cho 1521 URLs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping job details:  26%|██▌       | 389/1521 [06:29<08:00,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi nghiêm trọng khi xử lý URL https://careerviet.vn/vi/tim-viec-lam/chuyen-vien-ngan-hang-dau-tu-m-a.35C464F5.html: Page.goto: Timeout 45000ms exceeded.\n",
            "Call log:\n",
            "  - navigating to \"https://careerviet.vn/vi/tim-viec-lam/chuyen-vien-ngan-hang-dau-tu-m-a.35C464F5.html\", waiting until \"domcontentloaded\"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping job details:  64%|██████▎   | 966/1521 [08:46<02:17,  4.04it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cHCyD99vk2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}